{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG6302A - Lab 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies et declaration de variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import sys\n",
    "import time\n",
    "from code_analysis import ASTReader, AST_fragmentation\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "AST_PATH = \"ast\"  # Chemin vers les kits d'AST\n",
    "MIN_NODES_FILE = 100\n",
    "MIN_NODES_FRAGMENT = 10\n",
    "SIMILARITY_THRESHOLD_FILE = 0.30\n",
    "SIMILARITY_THRESHOLD_FRAGMENT = 0.10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Chargement et prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données AST...\n",
      "Taille de vecteur détectée : 127\n",
      "Nombre total de fichiers AST traités : 1690\n",
      "Nombre total de fragments extraits : 2902\n"
     ]
    }
   ],
   "source": [
    "# Trouve tous les fichiers .ast.json dans les sous-dossiers de base_path.\n",
    "def get_ast_files(base_path):\n",
    "    kit_files_map = collections.defaultdict(list)\n",
    "    kits = []\n",
    "    if not os.path.isdir(base_path):\n",
    "        print(f\"Erreur: Le dossier AST '{base_path}' n'existe pas.\")\n",
    "        return {}, []\n",
    "        \n",
    "    for dir_kit in sorted(os.listdir(base_path)):\n",
    "        kit_path = os.path.join(base_path, dir_kit)\n",
    "        if os.path.isdir(kit_path):\n",
    "            kits.append(dir_kit)\n",
    "            for root, _, files in os.walk(kit_path):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".ast.json\") or file.endswith(\".ast.json.gz\"):\n",
    "                        full_path = os.path.join(root, file)\n",
    "                        kit_files_map[dir_kit].append(full_path)\n",
    "    if not kits:\n",
    "        print(f\"Aucun sous-dossier (kit) trouvé dans '{base_path}'.\")\n",
    "    return kit_files_map, kits\n",
    "\n",
    "# Calcule la distance de Manhattan entre deux vecteurs numpy.\n",
    "def calculate_manhattan_distance(v1, v2):\n",
    "    return np.sum(np.abs(v1 - v2))\n",
    "\n",
    "def get_function_name(ast, fragment_node_id):\n",
    "    # Tente d'extraire le nom de la fonction/méthode d'un nœud fragment.\n",
    "    # chercher un enfant de type 'Id' qui pourrait être le nom\n",
    "    try:\n",
    "        children = ast.get_children(fragment_node_id)\n",
    "        for child_id in children:\n",
    "            # Souvent le nom est un Id ou similaire, directement enfant ou petit-enfant\n",
    "            if ast.get_type(child_id) == 'Id' and ast.get_image(child_id):\n",
    "                return ast.get_image(child_id)\n",
    "            # Parfois encapsulé dans un autre noeud (ex: ReturnValueFunction)\n",
    "            grandchildren = ast.get_children(child_id)\n",
    "            for grandchild_id in grandchildren:\n",
    "                 if ast.get_type(grandchild_id) == 'Id' and ast.get_image(grandchild_id):\n",
    "                     return ast.get_image(grandchild_id)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Si non trouvé, retourner une indication\n",
    "    node_type = ast.get_type(fragment_node_id)\n",
    "    return f\"[{node_type}_SansNomTrouve_{fragment_node_id}]\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Chargement des données AST...\")\n",
    "reader = ASTReader()\n",
    "kit_files_map, kits = get_ast_files(AST_PATH)\n",
    "\n",
    "all_files_data = [] \n",
    "all_fragments_data = [] \n",
    "\n",
    "asts_cache = {} # Cache pour éviter de relire les ASTs: {filepath: ast}\n",
    "def get_ast(path):\n",
    "    if path not in asts_cache:\n",
    "        asts_cache[path] = reader.read_ast(path)\n",
    "    return asts_cache[path]\n",
    "\n",
    "total_files_processed = 0\n",
    "total_fragments_processed = 0\n",
    "\n",
    "\n",
    "# Initialisation d'un AST pour obtenir la taille du vecteur\n",
    "try:\n",
    "    # Essayer de lire un fichier pour obtenir la structure AST et la taille du vecteur\n",
    "    first_kit = next(iter(kit_files_map)) if kit_files_map else None\n",
    "    first_file = kit_files_map[first_kit][0] if first_kit and kit_files_map[first_kit] else None\n",
    "    if first_file:\n",
    "        temp_ast = get_ast(first_file)\n",
    "        VECTOR_SIZE = len(temp_ast.types)\n",
    "        print(f\"Taille de vecteur détectée : {VECTOR_SIZE}\")\n",
    "        del temp_ast # vider la mémoire\n",
    "    else:\n",
    "        print(\"Aucun fichier AST trouvé pour déterminer la taille du vecteur. Arrêt.\")\n",
    "        sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la lecture initiale pour déterminer la taille du vecteur : {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "for kit_id in kits:\n",
    "    # print(f\"  Traitement du kit : {kit_id} ({len(kit_files_map[kit_id])} fichiers)\")\n",
    "    for filepath in kit_files_map[kit_id]:\n",
    "        try:\n",
    "            ast = get_ast(filepath)\n",
    "            asts_cache[filepath] = ast\n",
    "            total_files_processed += 1\n",
    "\n",
    "            file_vector = ast.vectorize()\n",
    "            file_node_count = int(file_vector.sum()) \n",
    "            if file_node_count > 0:\n",
    "                 all_files_data.append((filepath, kit_id, file_vector, file_node_count))\n",
    "\n",
    "            fragment_nodes = AST_fragmentation(ast)\n",
    "            \n",
    "            ast_for_fragments = get_ast(filepath)\n",
    "\n",
    "            for fragment_node_id in fragment_nodes:\n",
    "                 fragment_vector = ast_for_fragments.vectorize(node=fragment_node_id)\n",
    "                 fragment_node_count = int(fragment_vector.sum())\n",
    "                 if fragment_node_count > 0:\n",
    "                     function_name = get_function_name(ast_for_fragments, fragment_node_id)\n",
    "                     all_fragments_data.append((filepath, kit_id, fragment_node_id, fragment_vector, fragment_node_count, function_name))\n",
    "                     total_fragments_processed += 1\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"    Attention: Fichier non trouvé: {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Erreur lors du traitement de {filepath}: {e}\")\n",
    "\n",
    "print(f\"Nombre total de fichiers AST traités : {total_files_processed}\")\n",
    "print(f\"Nombre total de fragments extraits : {total_fragments_processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Analyse au niveau des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clones 'paramétriques' (Fichiers exacts, >100 nœuds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers avec > 100 nœuds : 899\n",
      "Taille du plus grand groupe de fichiers identiques : 47\n",
      "Exemples de fichiers dans ce groupe :\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/cc/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/info/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/start/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/1f7ebc62d330d7e48473470961169eb4/cc/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/1f7ebc62d330d7e48473470961169eb4/info/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/1f7ebc62d330d7e48473470961169eb4/start/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/2284e439f95ccee06d62fa62fb0f1b6f/cc/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/2284e439f95ccee06d62fa62fb0f1b6f/info/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/2284e439f95ccee06d62fa62fb0f1b6f/start/index.php.ast.json.gz (Kit: 2099)\n",
      "  - ast/2099/dhl/a1b2c3/3cf7cb38c0c3b2d62bc28e7891186988/cc/index.php.ast.json.gz (Kit: 2099)\n",
      "  ...\n",
      "Ils proviennent exclusivement de 2 kits: 2099, 4417\n"
     ]
    }
   ],
   "source": [
    "files_filtered = [(fp, k_id, vec, count) for fp, k_id, vec, count in all_files_data if count > MIN_NODES_FILE]\n",
    "print(f\"Nombre de fichiers avec > {MIN_NODES_FILE} nœuds : {len(files_filtered)}\")\n",
    "\n",
    "# Groupement par vecteur (ignorant les doublons intra-kit)\n",
    "vectors_files_exact = collections.defaultdict(list)\n",
    "for filepath, kit_id, vector, _ in files_filtered:\n",
    "    vector_tuple = tuple(vector)\n",
    "    vectors_files_exact[vector_tuple].append((filepath, kit_id))\n",
    "\n",
    "largest_group_files_exact = []\n",
    "if vectors_files_exact:\n",
    "    largest_group_files_exact = max(vectors_files_exact.values(), key=len)\n",
    "\n",
    "print(f\"Taille du plus grand groupe de fichiers identiques : {len(largest_group_files_exact)}\")\n",
    "if largest_group_files_exact:\n",
    "    print(\"Exemples de fichiers dans ce groupe :\")\n",
    "    for i, (fp, k_id) in enumerate(largest_group_files_exact[:10]):\n",
    "        print(f\"  - {fp} (Kit: {k_id})\")\n",
    "    if len(largest_group_files_exact) > 10:\n",
    "        print(\"  ...\")\n",
    "\n",
    "    kits_in_group = set(k_id for _, k_id in largest_group_files_exact)\n",
    "    print(f\"Ils proviennent exclusivement de {len(kits_in_group)} kits:\", \", \".join(sorted(kits_in_group)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarques concernant les fichiers:\n",
    "\n",
    "- Forte Duplication Intra-Kit : Le fait que le plus grand groupe contienne 47 fichiers mais ne provienne que de 2 kits (2099 et 4417) indique une duplication massive à l'intérieur de ces kits.\n",
    "- Structure Répétitive : Les exemples de chemins (.../cc/index.php, .../info/index.php, .../start/index.php, le tout répété sous différents répertoires avec des noms ressemblant à des hash : 082e..., 1f7ebc...) confirment cette duplication. Il semble que le même fichier (index.php dans ce cas, qui a plus de 100 nœuds AST) soit copié textuellement à de multiples endroits au sein de l'arborescence de ces kits.\n",
    "- Similarité Structurelle des Kits 2099 et 4417 : La présence de ces mêmes fichiers fortement dupliqués dans les deux kits suggère que ces kits sont très similaires, voire des copies l'un de l'autre, ou qu'ils partagent une base de code commune qui est simplement répliquée.\n",
    "- Nature \"Paramétrique\" : Bien que les fichiers soient identiques au niveau du vecteur (même nombre et type de nœuds AST), il pourrait y avoir des différences mineures non capturées par ce vecteur (ex: valeurs littérales de chaînes, commentaires). Cependant, la duplication exacte des chemins suggère plutôt des copies conformes. Ces index.php servent probablement des fonctions similaires (ex: collecte de \"cc\", \"info\", page \"start\") mais sont déployés dans des contextes (sous-dossiers) différents au sein du kit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refaire l'opération en ignorant les vecteurs dupliqués au sein d'un même kit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du plus grand groupe de kits partageant un fichier identique (après filtrage intra-kit) : 7\n",
      "Kits concernés : 0415, 0485, 1110, 1442, 3135, 3662, 3716\n"
     ]
    }
   ],
   "source": [
    "vectors_files_exact_unique_kit = collections.defaultdict(set)\n",
    "for filepath, kit_id, vector, _ in files_filtered:\n",
    "    vector_tuple = tuple(vector)\n",
    "    vectors_files_exact_unique_kit[vector_tuple].add(kit_id)\n",
    "\n",
    "largest_group_size_unique_kit = 0\n",
    "if vectors_files_exact_unique_kit:\n",
    "   largest_group_size_unique_kit = max(len(kits) for kits in vectors_files_exact_unique_kit.values())\n",
    "\n",
    "print(f\"Taille du plus grand groupe de kits partageant un fichier identique (après filtrage intra-kit) : {largest_group_size_unique_kit}\")\n",
    "\n",
    "kits_in_largest_groups = set()\n",
    "if largest_group_size_unique_kit > 0:\n",
    "    for vector_tuple, kit_id_set in vectors_files_exact_unique_kit.items():\n",
    "        if len(kit_id_set) == largest_group_size_unique_kit:\n",
    "            kits_in_largest_groups.update(kit_id_set)\n",
    "\n",
    "print(f\"Kits concernés : {', '.join(sorted(list(kits_in_largest_groups)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela indique une réutilisation de code inter-kits. Un fichier spécifique (probablement un composant standardisé comme un script anti-bot) est cloné tel quel et intégré dans au moins 7 kits de phishing différents, suggérant soit un auteur commun, soit le partage/vente de composants entre différents acteurs malveillants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fichiers similaires (>100 nœuds, distance <= 30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul des similarités par paires pour 899 fichiers...\n",
      "Taille du plus grand groupe de fichiers similaires trouvé : 81\n",
      "Exemples de fichiers dans ce groupe similaire :\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/cc/index.php.ast.json.gz (Kit: 2099, Nœuds: 207)\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/info/index.php.ast.json.gz (Kit: 2099, Nœuds: 207)\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/start/index.php.ast.json.gz (Kit: 2099, Nœuds: 207)\n",
      "  - ast/2099/dhl/a1b2c3/082e3739ba7c5489ea1c9eee2d64ecf7/vbv/index.php.ast.json.gz (Kit: 2099, Nœuds: 218)\n",
      "  - ast/2099/dhl/a1b2c3/1f7ebc62d330d7e48473470961169eb4/cc/index.php.ast.json.gz (Kit: 2099, Nœuds: 207)\n",
      "  ...\n",
      "\n",
      "Ce groupe de fichiers similaires provient de 3 kits différents.\n",
      "Kits concernés : 2099, 2110, 4417\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_files = len(files_filtered)\n",
    "similarity_groups = collections.defaultdict(list)\n",
    "\n",
    "if n_files > 1:\n",
    "    print(f\"Calcul des similarités par paires pour {n_files} fichiers...\")\n",
    "    for i in range(n_files):\n",
    "        filepath_i, kit_id_i, vector_i, node_count_i = files_filtered[i]\n",
    "        similarity_groups[i].append(i)\n",
    "        threshold = SIMILARITY_THRESHOLD_FILE * node_count_i\n",
    "\n",
    "        for j in range(i + 1, n_files):\n",
    "            filepath_j, kit_j, vector_j, node_count_j = files_filtered[j]\n",
    "\n",
    "            distance = calculate_manhattan_distance(vector_i, vector_j)\n",
    "\n",
    "            # Vérifier si similaire par rapport à i OU j\n",
    "            threshold_j = SIMILARITY_THRESHOLD_FILE * node_count_j\n",
    "            if distance <= threshold or distance <= threshold_j:\n",
    "                 # Ils sont considérés comme similaires\n",
    "                 similarity_groups[i].append(j)\n",
    "                 similarity_groups[j].append(i)\n",
    "else:\n",
    "    print(\"Pas assez de fichiers (>1) pour comparer la similarité.\")\n",
    "\n",
    "largest_group_files_similar_indices = []\n",
    "if similarity_groups:\n",
    "    center_index = max(similarity_groups, key=lambda k: len(similarity_groups[k]))\n",
    "    largest_group_files_similar_indices = similarity_groups[center_index]\n",
    "\n",
    "print(f\"Taille du plus grand groupe de fichiers similaires trouvé : {len(largest_group_files_similar_indices)}\")\n",
    "if largest_group_files_similar_indices:\n",
    "    print(\"Exemples de fichiers dans ce groupe similaire :\")\n",
    "    representative_files = [files_filtered[idx] for idx in largest_group_files_similar_indices[:5]]\n",
    "    for i, (fp, k_id, vec, count) in enumerate(representative_files):\n",
    "        print(f\"  - {fp} (Kit: {k_id}, Nœuds: {count})\")\n",
    "    if len(largest_group_files_similar_indices) > 5:\n",
    "        print(\"  ...\")\n",
    "\n",
    "    kits_in_similar_group = set(files_filtered[idx][1] for idx in largest_group_files_similar_indices)\n",
    "    print(f\"\\nCe groupe de fichiers similaires provient de {len(kits_in_similar_group)} kits différents.\")\n",
    "    print(f\"Kits concernés : {', '.join(sorted(list(kits_in_similar_group)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Analyse au niveau des fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Clones 'paramétriques' (Fragments exacts, >10 nœuds, hors duplicats intra-kit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fragments avec > 10 nœuds : 2553\n",
      "\n",
      "Le fragment le plus dupliqué (structure exacte) est présent dans 12 kits différents.\n",
      "- Kits concernés : 0009, 0229, 1110, 1651, 2070, 2099, 2110, 3180, 3548, 3676, 4218, 4417\n",
      "Nom(s) de fonction/méthode associés à ce fragment : dublicate, recurse_copy\n",
      "Exemple d'occurrence : Fichier 'ast/0009/CA 3.0/CA 3.0/index.php.ast.json.gz', Nœud fragment ID: 7785818\n"
     ]
    }
   ],
   "source": [
    "fragments_filtered = [(fp, k_id, f_id, vec, count, name) for fp, k_id, f_id, vec, count, name in all_fragments_data if count > MIN_NODES_FRAGMENT]\n",
    "print(f\"Nombre de fragments avec > {MIN_NODES_FRAGMENT} nœuds : {len(fragments_filtered)}\")\n",
    "\n",
    "# Groupement par vecteur, en ne comptant chaque kit qu'une fois par vecteur\n",
    "vectors_fragments_exact_unique_kit = collections.defaultdict(lambda: {'kits': set(), 'names': set(), 'examples': []})\n",
    "processed_frag_kit_vector = set()\n",
    "\n",
    "for filepath, kit_id, frag_id, vector, count, name in fragments_filtered:\n",
    "    vector_tuple = tuple(vector)\n",
    "    frag_kit_vector_key = (kit_id, vector_tuple)\n",
    "\n",
    "    if frag_kit_vector_key not in processed_frag_kit_vector:\n",
    "        vectors_fragments_exact_unique_kit[vector_tuple]['kits'].add(kit_id)\n",
    "        if name:\n",
    "             vectors_fragments_exact_unique_kit[vector_tuple]['names'].add(name)\n",
    "        if len(vectors_fragments_exact_unique_kit[vector_tuple]['examples']) < 1:\n",
    "             vectors_fragments_exact_unique_kit[vector_tuple]['examples'].append((filepath, frag_id))\n",
    "        processed_frag_kit_vector.add(frag_kit_vector_key)\n",
    "\n",
    "most_duplicated_fragment_info = None\n",
    "max_kits_count = 0\n",
    "if vectors_fragments_exact_unique_kit:\n",
    "    most_duplicated_vector_tuple = max(vectors_fragments_exact_unique_kit,\n",
    "                                       key=lambda k: len(vectors_fragments_exact_unique_kit[k]['kits']))\n",
    "    most_duplicated_fragment_info = vectors_fragments_exact_unique_kit[most_duplicated_vector_tuple]\n",
    "    max_kits_count = len(most_duplicated_fragment_info['kits'])\n",
    "\n",
    "\n",
    "print(f\"\\nLe fragment le plus dupliqué (structure exacte) est présent dans {max_kits_count} kits différents.\")\n",
    "print(f\"- Kits concernés : {', '.join(sorted(list(most_duplicated_fragment_info['kits'])))}\")\n",
    "\n",
    "if most_duplicated_fragment_info:\n",
    "    # Question: Quelle est le nom(s) de la fonction correspondant à ce fragment ?\n",
    "    fragment_names = most_duplicated_fragment_info['names']\n",
    "    if fragment_names:\n",
    "        print(f\"Nom(s) de fonction/méthode associés à ce fragment : {', '.join(sorted(list(fragment_names)))}\")\n",
    "    else:\n",
    "        print(\"Aucun nom de fonction/méthode n'a pu être extrait pour ce fragment.\")\n",
    "    example_fp, example_fid = most_duplicated_fragment_info['examples'][0]\n",
    "    print(f\"Exemple d'occurrence : Fichier '{example_fp}', Nœud fragment ID: {example_fid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fragment de code le plus dupliqué, présent dans 12 kits, est une fonction de copie récursive (`dublicate` et `recurse_copy`) largement réutilisée. Cela peux indiquer une approche modulaire et du partage de composants entre groupes de phishing. Malgré des noms différents, la structure du code reste identique, signe de réutilisation avec légères modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Fragments similaires (>10 nœuds, distance <= 10%, hors duplicats intra-kit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fragments uniques par kit (avec > 10 nœuds) à comparer : 1930\n",
      "Calcul des similarités par paires pour 1930 fragments uniques par kit...\n",
      "\n",
      "Taille du plus grand groupe de fragments similaires trouvé (inter-kit) : 16\n",
      "Exemples de fragments dans ce groupe similaire :\n",
      "  - Nom: 'getOS', Kit: 0109, Fichier: ast/0109/cappy/s/Bots/bot/Antibot/Module/Setmodule.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'get_user_os', Kit: 0229, Fichier: ast/0229/io/Login/inc/functions.php.ast.json.gz, Nœuds: 84\n",
      "  - Nom: 'getOS', Kit: 0406, Fichier: ast/0406/VYSTARBANK[MRWEEBEE]/dead.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'getOs', Kit: 0415, Fichier: ast/0415/M&T/darkx/recon.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'getOS', Kit: 0431, Fichier: ast/0431/includes/userinfo.php.ast.json.gz, Nœuds: 82\n",
      "  - Nom: 'XB_OS', Kit: 0481, Fichier: ast/0481/mazon/amazon/XBALTI/get_browser.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'getOs', Kit: 1033, Fichier: ast/1033/M&T/M&T/darkx/recon.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'get_user_os', Kit: 1110, Fichier: ast/1110/submit/inc/functions.php.ast.json.gz, Nœuds: 84\n",
      "  - Nom: 'XB_OS', Kit: 1442, Fichier: ast/1442/web/auth/XBALTI/send.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'get_user_os', Kit: 1651, Fichier: ast/1651/inc/functions.php.ast.json.gz, Nœuds: 84\n",
      "  - Nom: 'getOS', Kit: 1926, Fichier: ast/1926/CITIZ/dead.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'XB_OS', Kit: 2866, Fichier: ast/2866/mazon/amazon/XBALTI/get_browser.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'X_OS', Kit: 3148, Fichier: ast/3148/ofc/BOTS/get_browser.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'getOs', Kit: 3716, Fichier: ast/3716/gruposantander/home/xREPORT/HOSTER.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'getOs', Kit: 3858, Fichier: ast/3858/onlineaqs.wellsfargo.us/Spox/Functions/Fuck-you.php.ast.json.gz, Nœuds: 81\n",
      "  - Nom: 'XB_OS', Kit: 4273, Fichier: ast/4273/mazon/amazon/XBALTI/get_browser.php.ast.json.gz, Nœuds: 81\n",
      "  ...\n",
      "\n",
      "Nom(s) de fonction/méthode associés à ces fragments similaires : XB_OS, X_OS, getOS, getOs, get_user_os\n"
     ]
    }
   ],
   "source": [
    "unique_fragments_per_kit = {}\n",
    "for filepath, kit_id, frag_id, vector, count, name in fragments_filtered:\n",
    "    vector_tuple = tuple(vector)\n",
    "    key = (vector_tuple, kit_id)\n",
    "    if key not in unique_fragments_per_kit:\n",
    "         unique_fragments_per_kit[key] = (vector, kit_id, name, filepath, count)\n",
    "\n",
    "fragments_to_compare = list(unique_fragments_per_kit.values())\n",
    "n_fragments = len(fragments_to_compare)\n",
    "print(f\"Nombre de fragments uniques par kit (avec > {MIN_NODES_FRAGMENT} nœuds) à comparer : {n_fragments}\")\n",
    "\n",
    "similarity_groups_frags = collections.defaultdict(list)\n",
    "\n",
    "if n_fragments > 1:\n",
    "    print(f\"Calcul des similarités par paires pour {n_fragments} fragments uniques par kit...\")\n",
    "    for i in range(n_fragments):\n",
    "        vector_i, kit_id_i, name_i, fp_i, node_count_i = fragments_to_compare[i]\n",
    "        similarity_groups_frags[i].append(i)\n",
    "        threshold = SIMILARITY_THRESHOLD_FRAGMENT * node_count_i\n",
    "\n",
    "        for j in range(i + 1, n_fragments):\n",
    "            vector_j, kit_id_j, name_j, fp_j, node_count_j = fragments_to_compare[j]\n",
    "\n",
    "            if kit_id_i == kit_id_j:\n",
    "                 continue # On ignore la similarité intra-kit ici\n",
    "\n",
    "            distance = calculate_manhattan_distance(vector_i, vector_j)\n",
    "            threshold_j = SIMILARITY_THRESHOLD_FRAGMENT * node_count_j\n",
    "\n",
    "            if distance <= threshold or distance <= threshold_j:\n",
    "                 similarity_groups_frags[i].append(j)\n",
    "                 similarity_groups_frags[j].append(i)\n",
    "else:\n",
    "     print(\"Pas assez de fragments uniques par kit (>1).\")\n",
    "\n",
    "\n",
    "largest_group_frags_similar_indices = []\n",
    "if similarity_groups_frags:\n",
    "    center_index_frag = max(similarity_groups_frags, key=lambda k: len(similarity_groups_frags[k]))\n",
    "    largest_group_frags_similar_indices = similarity_groups_frags[center_index_frag]\n",
    "\n",
    "print(f\"\\nTaille du plus grand groupe de fragments similaires trouvé (inter-kit) : {len(largest_group_frags_similar_indices)}\")\n",
    "\n",
    "if largest_group_frags_similar_indices:\n",
    "    names_in_similar_group = set()\n",
    "    representative_frags = []\n",
    "    for idx in largest_group_frags_similar_indices:\n",
    "         frag_data = fragments_to_compare[idx]\n",
    "         representative_frags.append(frag_data)\n",
    "         if frag_data[2]:\n",
    "              names_in_similar_group.add(frag_data[2])\n",
    "\n",
    "    print(\"Exemples de fragments dans ce groupe similaire :\")\n",
    "    for i, (vec, k_id, name, fp, count) in enumerate(representative_frags):\n",
    "        print(f\"  - Nom: '{name}', Kit: {k_id}, Fichier: {fp}, Nœuds: {count}\")\n",
    "    if len(largest_group_frags_similar_indices) > 5:\n",
    "        print(\"  ...\")\n",
    "\n",
    "    if names_in_similar_group:\n",
    "        print(f\"\\nNom(s) de fonction/méthode associés à ces fragments similaires : {', '.join(sorted(list(names_in_similar_group)))}\")\n",
    "    else:\n",
    "        print(\"\\nAucun nom de fonction/méthode n'a pu être extrait pour les fragments de ce groupe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La détection du système d'exploitation est vraisemblablement une fonctionnalité très commune, présente sous des formes très similaires (mais pas identiques) dans au moins 16 kits différents. Cela met en évidence la variabilité des implémentations (légères modifications structurelles, conventions de nommage diverses) tout en soulignant la réutilisation massive d'un concept et d'une logique de base à travers des kits de phishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Analyse au niveau des kits 'paramétriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul des vecteurs représentatifs des kits (somme des fragments)...\n",
      "62 kits ont au moins un fragment et ont un vecteur représentatif.\n",
      "\n",
      "Taille du plus grand groupe de kits ayant des vecteurs représentatifs identiques : 3\n",
      "Kits dans ce groupe : 0398, 0556, 2784\n",
      "Nombre de fragments détectés : 3.\n"
     ]
    }
   ],
   "source": [
    "kit_vectors_sum = collections.defaultdict(lambda: np.zeros(VECTOR_SIZE, dtype=int))\n",
    "kit_fragment_count = collections.defaultdict(int)\n",
    "\n",
    "print(\"Calcul des vecteurs représentatifs des kits (somme des fragments)...\")\n",
    "for filepath, kit_id, frag_id, vector, count, name in all_fragments_data:\n",
    "     kit_vectors_sum[kit_id] += vector\n",
    "     kit_fragment_count[kit_id] += 1\n",
    "\n",
    "print(f\"{len(kit_vectors_sum)} kits ont au moins un fragment et ont un vecteur représentatif.\")\n",
    "\n",
    "kit_vector_groups = collections.defaultdict(list)\n",
    "for kit_id, sum_vector in kit_vectors_sum.items():\n",
    "    if sum_vector.sum() > 0:\n",
    "        vector_tuple = tuple(sum_vector)\n",
    "        kit_vector_groups[vector_tuple].append(kit_id)\n",
    "\n",
    "largest_group_kits_exact = []\n",
    "if kit_vector_groups:\n",
    "     largest_group_kits_exact = max(kit_vector_groups.values(), key=len)\n",
    "\n",
    "print(f\"\\nTaille du plus grand groupe de kits ayant des vecteurs représentatifs identiques : {len(largest_group_kits_exact)}\")\n",
    "\n",
    "if largest_group_kits_exact:\n",
    "    # Question: Quels sont ces kits?\n",
    "    print(f\"Kits dans ce groupe : {', '.join(sorted(largest_group_kits_exact))}\")\n",
    "\n",
    "    # Question: Y a-t-il des différences entre ces kits au niveaux des types des nœuds de l'AST (type, image)?\n",
    "\n",
    "    # On vérifie si le nombre de fragments est aussi identique (indice supplémentaire)\n",
    "    num_fragments_in_group = [kit_fragment_count[k] for k in largest_group_kits_exact]\n",
    "    print(f\"Nombre de fragments détectés : {num_fragments_in_group[0]}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En se basant sur le vecteur somme des fragments :\n",
    "\n",
    "- Il n'y a pas de différence dans la distribution globale des types de nœuds AST entre les kits 0398, 0556 et 2784.\n",
    "\n",
    "- Il peut y avoir des différences au niveau de l'image (contenu textuel) des nœuds, car cette information n'est pas capturée par le vecteur.\n",
    "\n",
    "Malgré la possibilité théorique de différences, le fait que les vecteurs sommes et le nombre de fragments soient identiques suggère que ces trois kits sont des copies très proches, voire quasi identiques, au moins au niveau du code source qui a été fragmenté et analysé. De plus, tous les kits de ce groupe ont le même nombre de fragments détectés: 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
